{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0b247f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjtonglet\u001b[0m (\u001b[33mbenchmark-nlp\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Saiga\\Documents\\NotebooksJupyter\\text_classification_benchmark\\notebooks\\hyperopt\\rf_opt\\wandb\\run-20221011_105658-2a45sesd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/benchmark-nlp/hyperopt/runs/2a45sesd\" target=\"_blank\">emotion datasets rf</a></strong> to <a href=\"https://wandb.ai/benchmark-nlp/hyperopt\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/benchmark-nlp/hyperopt/runs/2a45sesd?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x1c811223bb0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Connect to wandb\n",
    "#TO DO : how to save models on the weight and bias platform\n",
    "import wandb\n",
    "wandb.login()\n",
    "wandb.init(project=\"hyperopt\", \n",
    "           entity=\"benchmark-nlp\",\n",
    "           name='emotion datasets rf') #CHANGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81b40cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f333de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load packages\n",
    "import warnings\n",
    "import io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from codecarbon import EmissionsTracker\n",
    "import yaml\n",
    "from util.dataloader import DataLoader\n",
    "from preprocessing.preprocessor import Preprocessor\n",
    "from util.datasplitter import data_splitter\n",
    "from preprocessing.fasttext_embeddings import FastTextEmbeddings\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, average_precision_score\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0b20476",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set constant values\n",
    "SEED=42 \n",
    "OPT_ITER=10  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2564a2",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b411fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3257 rows preprocessed in 3.36051344871521 seconds\n",
      "The history saving thread hit an unexpected error (OperationalError('database is locked')).History will not be written to the database.\n",
      "1421 rows preprocessed in 0.7274329662322998 seconds\n",
      "374 rows preprocessed in 0.17652130126953125 seconds\n",
      "16000 rows preprocessed in 9.768099546432495 seconds\n",
      "2000 rows preprocessed in 0.9235284328460693 seconds\n",
      "2000 rows preprocessed in 0.9534504413604736 seconds\n",
      "87170 rows preprocessed in 37.308165073394775 seconds\n",
      "7740 rows preprocessed in 4.651559352874756 seconds\n",
      "8069 rows preprocessed in 3.3959197998046875 seconds\n"
     ]
    }
   ],
   "source": [
    "dl = DataLoader(['emotion'])\n",
    "data = dl.load()\n",
    "\n",
    "\n",
    "tweet_preprocessor = Preprocessor(is_tweet=True)\n",
    "preprocessor = Preprocessor()\n",
    "\n",
    "#We are not interested in the test sets for hyperparameter optimization\n",
    "train_eval_emotion, val_eval_emotion, _ = data_splitter(data['tweetEval'],\n",
    "                                 tweet_preprocessor,  #Need to rerun this one\n",
    "                                 create_val_set=True,   #No validation set is provided\n",
    "                                 seed=SEED)\n",
    "train_carer, val_carer, _ = data_splitter(data['CARER'],\n",
    "                                 preprocessor, \n",
    "                                 create_val_set=True,   #No validation set is provided\n",
    "                                 seed=SEED)\n",
    "train_silicone, val_silicone, _ = data_splitter(data['silicone'],\n",
    "                                 preprocessor, \n",
    "                                 create_val_set=True,   #No validation set is provided\n",
    "                                 seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "010d1fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#fasttext \n",
    "fasttext = FastTextEmbeddings()\n",
    "fasttext.load_model('fasttext/cc.en.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02866a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to generate sentence embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 3257/3257 [00:27<00:00, 116.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to generate sentence embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 374/374 [00:03<00:00, 124.21it/s]\n"
     ]
    }
   ],
   "source": [
    "embedded_train_eval_emotion = fasttext.generate_sentence_embeddings(train_eval_emotion['text'])\n",
    "embedded_val_eval_emotion = fasttext.generate_sentence_embeddings(val_eval_emotion['text'])\n",
    "embedded_train_eval_emotion['label'] = train_eval_emotion['label'].to_list()\n",
    "embedded_val_eval_emotion['label'] = val_eval_emotion['label'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa8081fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to generate sentence embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 16000/16000 [00:37<00:00, 430.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to generate sentence embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:05<00:00, 339.83it/s]\n"
     ]
    }
   ],
   "source": [
    "embedded_train_carer = fasttext.generate_sentence_embeddings(train_carer['text'])\n",
    "embedded_val_carer = fasttext.generate_sentence_embeddings(val_carer['text'])\n",
    "embedded_train_carer['label'] = train_carer['label'].to_list()\n",
    "embedded_val_carer['label'] = val_carer['label'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72d0c50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to generate sentence embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 87170/87170 [03:11<00:00, 455.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to generate sentence embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 8069/8069 [00:15<00:00, 510.85it/s]\n"
     ]
    }
   ],
   "source": [
    "embedded_train_silicone = fasttext.generate_sentence_embeddings(train_silicone['text'])\n",
    "embedded_val_silicone = fasttext.generate_sentence_embeddings(val_silicone['text'])\n",
    "embedded_train_silicone['label'] = train_silicone['label'].to_list()\n",
    "embedded_val_silicone['label'] = val_silicone['label'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b151bc98",
   "metadata": {},
   "source": [
    "## Hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "224ad24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "#Load the template yaml sweep config file for logistic regression\n",
    "#If the value range for an hyperparameter needs to be changed, better to do it in the .yaml file than in a notebook\n",
    "with open(\"config/rf_sweep.yaml\", 'r') as stream:\n",
    "    sweep_config = yaml.safe_load(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "114df105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'method': 'random',\n",
       " 'entity': 'benchmark-nlp',\n",
       " 'project': 'hyperopt',\n",
       " 'metric': {'name': 'loss', 'goal': 'minimize'},\n",
       " 'parameters': {'C': {'min': 0, 'max': 10, 'distribution': 'uniform'},\n",
       "  'penalty': {'value': 'l2'},\n",
       "  'solver': {'value': 'lbfgs'},\n",
       "  'random_state': {'value': 42}}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The config is displayed as a nested dictionary\n",
    "sweep_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f1c508",
   "metadata": {},
   "source": [
    "#### eval emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9636bd33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Don't forget to name the sweep instance  \n",
    "name = 'rf_tfidf_eval_emotion' #change here\n",
    "sweep_config['name'] =  name\n",
    "\n",
    "#Generate a sweep_id\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"hyperopt\")\n",
    "\n",
    "def train_tfidf(config = None,\n",
    "          train=train_eval_emotion, #Change here\n",
    "          val=val_eval_emotion): #change here\n",
    "    '''\n",
    "    Generic WandB function to conduct hyperparameter optimization with tf-idf vectorizer\n",
    "    '''\n",
    "    # Initialize a new wandb run\n",
    "    with wandb.init(config=config,group=name):\n",
    "        # If called by wandb.agent, as below,\n",
    "        # this config will be set by Sweep Controller\n",
    "        config = wandb.config\n",
    "        vec = TfidfVectorizer()\n",
    "        clf = RandomForestClassifier(n_estimators=config.n_estimators,\n",
    "                                max_features=config.max_features,\n",
    "                                 random_state=config.random_state) #set the hyperparams here\n",
    "        #Create the pipeline\n",
    "        pipe = Pipeline([('vectorizer',vec),('clf',clf)])\n",
    "        #Fit the pipeline\n",
    "        pipe.fit(train['text'],train['label'])\n",
    "        \n",
    "        #Make predictions\n",
    "        pred_val = pipe.predict(val['text'])\n",
    "        pred_prob_val = pipe.predict_proba(val['text'])[:,1]\n",
    "        accuracy = accuracy_score(val['label'],pred_val)\n",
    "        f1_macro = f1_score(val['label'],pred_val,average='macro')\n",
    "        if train['label'].nunique() <=2:\n",
    "            aucpc =  average_precision_score(val['label'],pred_prob_val)\n",
    "            auc = roc_auc_score(val['label'],pred_prob_val)\n",
    "        else:\n",
    "            aucpc = '-'\n",
    "            auc = '-'\n",
    "        #Log metrics on WandB\n",
    "        wandb.log({\"accuracy\": accuracy, \"f1 macro\":f1_macro, \"AUC-PC\":aucpc, 'AUC':auc })\n",
    "\n",
    "#Track emissions\n",
    "tracker = EmissionsTracker(project_name=name,log_level='warning', measure_power_secs=300,\n",
    "                           output_file='output/emissions_hyperopt.csv')\n",
    "#Launch the agent\n",
    "tracker.start()\n",
    "wandb.agent(sweep_id, train_tfidf,count=OPT_ITER) #Count : number of iterations\n",
    "tracker.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d149865",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Don't forget to name the sweep instance   \n",
    "name = 'rf_ft_eval_emotion' #change here\n",
    "sweep_config['name'] = name\n",
    "#Generate a sweep_id\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"hyperopt\")\n",
    "\n",
    "def train_fasttext(config = None,\n",
    "          train=embedded_train_eval_emotion, #Change here\n",
    "          val=embedded_val_eval_emotion): #change here\n",
    "    # Initialize a new wandb run\n",
    "    with wandb.init(config=config, group=name):\n",
    "        # If called by wandb.agent, as below,\n",
    "        # this config will be set by Sweep Controller\n",
    "        config = wandb.config\n",
    "\n",
    "        clf = RandomForestClassifier(n_estimators=config.n_estimators,\n",
    "                                max_features=config.max_features,\n",
    "                                 random_state=config.random_state) #set the hyperparams here\n",
    "        pipe = Pipeline([('clf',clf)])\n",
    "        pipe.fit(train.fillna(0).drop(['label'],axis=1),train['label'])\n",
    "        \n",
    "        #Make predictions\n",
    "        pred_val = pipe.predict(val.fillna(0).drop(['label'],axis=1))\n",
    "        pred_prob_val = pipe.predict_proba(val.fillna(0).drop(['label'],axis=1))[:,1]\n",
    "        accuracy = accuracy_score(val['label'],pred_val)\n",
    "        f1_macro = f1_score(val['label'],pred_val,average='macro')\n",
    "        if train['label'].nunique() <=2:\n",
    "            aucpc =  average_precision_score(val['label'],pred_prob_val)\n",
    "            auc = roc_auc_score(val['label'],pred_prob_val)\n",
    "            #Log predictions on WandB\n",
    "        else:\n",
    "            aucpc = '-'\n",
    "            auc = '-'\n",
    "        wandb.log({\"accuracy\": accuracy, \"f1 macro\":f1_macro, \"AUC-PC\":aucpc, 'AUC':auc })\n",
    "\n",
    "\n",
    "#Track emissions\n",
    "tracker = EmissionsTracker(project_name=name,log_level='warning', measure_power_secs=300,\n",
    "                           output_file='output/emissions_hyperopt.csv')\n",
    "#Launch the agent\n",
    "tracker.start()\n",
    "wandb.agent(sweep_id, train_fasttext,count=OPT_ITER)\n",
    "tracker.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fbc6d7",
   "metadata": {},
   "source": [
    "#### CARER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469357b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Don't forget to name the sweep instance  \n",
    "name = 'rf_tfidf_carer' #change here\n",
    "sweep_config['name'] =  name\n",
    "\n",
    "#Generate a sweep_id\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"hyperopt\")\n",
    "\n",
    "def train_tfidf(config = None,\n",
    "          train=train_carer, #Change here\n",
    "          val=val_carer): #change here\n",
    "    '''\n",
    "    Generic WandB function to conduct hyperparameter optimization with tf-idf vectorizer\n",
    "    '''\n",
    "    # Initialize a new wandb run\n",
    "    with wandb.init(config=config,group=name):\n",
    "        # If called by wandb.agent, as below,\n",
    "        # this config will be set by Sweep Controller\n",
    "        config = wandb.config\n",
    "        vec = TfidfVectorizer()\n",
    "        clf = RandomForestClassifier(n_estimators=config.n_estimators,\n",
    "                   \n",
    "                                max_features=config.max_features,\n",
    "\n",
    "                                 random_state=config.random_state) #set the hyperparams here\n",
    "        #Create the pipeline\n",
    "        pipe = Pipeline([('vectorizer',vec),('clf',clf)])\n",
    "        #Fit the pipeline\n",
    "        pipe.fit(train['text'],train['label'])\n",
    "        \n",
    "        #Make predictions\n",
    "        pred_val = pipe.predict(val['text'])\n",
    "        pred_prob_val = pipe.predict_proba(val['text'])[:,1]\n",
    "        accuracy = accuracy_score(val['label'],pred_val)\n",
    "        f1_macro = f1_score(val['label'],pred_val,average='macro')\n",
    "        if train['label'].nunique() <=2:\n",
    "            aucpc =  average_precision_score(val['label'],pred_prob_val)\n",
    "            auc = roc_auc_score(val['label'],pred_prob_val)\n",
    "        else:\n",
    "            aucpc = '-'\n",
    "            auc = '-'\n",
    "        #Log metrics on WandB\n",
    "        wandb.log({\"accuracy\": accuracy, \"f1 macro\":f1_macro, \"AUC-PC\":aucpc, 'AUC':auc })\n",
    "\n",
    "#Track emissions\n",
    "tracker = EmissionsTracker(project_name=name,log_level='warning', measure_power_secs=300,\n",
    "                           output_file='output/emissions_hyperopt.csv')\n",
    "#Launch the agent\n",
    "tracker.start()\n",
    "wandb.agent(sweep_id, train_tfidf,count=OPT_ITER)\n",
    "tracker.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830c6068",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Don't forget to name the sweep instance   \n",
    "name = 'rf_ft_carer' #CHANGE HERE\n",
    "sweep_config['name'] = name\n",
    "#Generate a sweep_id\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"hyperopt\")\n",
    "\n",
    "def train_fasttext(config = None,\n",
    "          train=embedded_train_carer, #CHANGE HERE\n",
    "          val=embedded_val_carer): #CHANGE HERE\n",
    "    # Initialize a new wandb run\n",
    "    with wandb.init(config=config, group=name):\n",
    "        config = wandb.config\n",
    "        clf = RandomForestClassifier(n_estimators=config.n_estimators,\n",
    "                                max_features=config.max_features,\n",
    "                                 random_state=config.random_state) #set the hyperparams here\n",
    "        pipe = Pipeline([('clf',clf)])\n",
    "        pipe.fit(train.fillna(0).drop(['label'],axis=1),train['label'])\n",
    "        \n",
    "        #Make predictions\n",
    "        pred_val = pipe.predict(val.fillna(0).drop(['label'],axis=1))\n",
    "        pred_prob_val = pipe.predict_proba(val.fillna(0).drop(['label'],axis=1))[:,1]\n",
    "        accuracy = accuracy_score(val['label'],pred_val)\n",
    "        f1_macro = f1_score(val['label'],pred_val,average='macro')\n",
    "        if train['label'].nunique() <=2:\n",
    "            aucpc =  average_precision_score(val['label'],pred_prob_val)\n",
    "            auc = roc_auc_score(val['label'],pred_prob_val)\n",
    "            #Log predictions on WandB\n",
    "        else:\n",
    "            aucpc = '-'\n",
    "            auc = '-'\n",
    "        wandb.log({\"accuracy\": accuracy, \"f1 macro\":f1_macro, \"AUC-PC\":aucpc, 'AUC':auc })\n",
    "\n",
    "\n",
    "#Track emissions\n",
    "tracker = EmissionsTracker(project_name=name,log_level='warning', measure_power_secs=300,\n",
    "                           output_file='output/emissions_hyperopt.csv')\n",
    "#Launch the agent\n",
    "tracker.start()\n",
    "wandb.agent(sweep_id, train_fasttext,count=OPT_ITER)\n",
    "tracker.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71a6f28",
   "metadata": {},
   "source": [
    "#### silicone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43086bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Don't forget to name the sweep instance  \n",
    "name = 'rf_tfidf_silicone' #change here\n",
    "sweep_config['name'] =  name\n",
    "\n",
    "#Generate a sweep_id\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"hyperopt\")\n",
    "\n",
    "def train_tfidf(config = None,\n",
    "          train=train_silicone, #Change here\n",
    "          val=val_silicone): #change here\n",
    "    '''\n",
    "    Generic WandB function to conduct hyperparameter optimization with tf-idf vectorizer\n",
    "    '''\n",
    "    # Initialize a new wandb run\n",
    "    with wandb.init(config=config,group=name):\n",
    "        # If called by wandb.agent, as below,\n",
    "        # this config will be set by Sweep Controller\n",
    "        config = wandb.config\n",
    "        vec = TfidfVectorizer()\n",
    "        clf = RandomForestClassifier(n_estimators=config.n_estimators,\n",
    "                                max_features=config.max_features,\n",
    "                                 random_state=config.random_state) #set the hyperparams here\n",
    "        \n",
    "        #Create the pipeline\n",
    "        pipe = Pipeline([('vectorizer',vec),('clf',clf)])\n",
    "        #Fit the pipeline\n",
    "        pipe.fit(train['text'],train['label'])\n",
    "        \n",
    "        #Make predictions\n",
    "        pred_val = pipe.predict(val['text'])\n",
    "        pred_prob_val = pipe.predict_proba(val['text'])[:,1]\n",
    "        accuracy = accuracy_score(val['label'],pred_val)\n",
    "        f1_macro = f1_score(val['label'],pred_val,average='macro')\n",
    "        if train['label'].nunique() <=2:\n",
    "            aucpc =  average_precision_score(val['label'],pred_prob_val)\n",
    "            auc = roc_auc_score(val['label'],pred_prob_val)\n",
    "        else:\n",
    "            aucpc = '-'\n",
    "            auc = '-'\n",
    "        #Log metrics on WandB\n",
    "        wandb.log({\"accuracy\": accuracy, \"f1 macro\":f1_macro, \"AUC-PC\":aucpc, 'AUC':auc })\n",
    "\n",
    "#Track emissions\n",
    "tracker = EmissionsTracker(project_name=name,log_level='warning', measure_power_secs=300,\n",
    "                           output_file='output/emissions_hyperopt.csv')\n",
    "#Launch the agent\n",
    "tracker.start()\n",
    "wandb.agent(sweep_id, train_tfidf, count=OPT_ITER)\n",
    "tracker.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c304fc6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Don't forget to name the sweep instance   \n",
    "name = 'rf_ft_silicone' #CHANGE HERE\n",
    "sweep_config['name'] = name\n",
    "#Generate a sweep_id\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"hyperopt\")\n",
    "\n",
    "def train_fasttext(config = None,\n",
    "          train=embedded_train_silicone, #CHANGE HERE\n",
    "          val=embedded_val_silicone): #CHANGE HERE\n",
    "    # Initialize a new wandb run\n",
    "    with wandb.init(config=config, group=name):\n",
    "        config = wandb.config\n",
    "        clf = RandomForestClassifier(n_estimators=config.n_estimators,\n",
    "                                max_features=config.max_features,\n",
    "                                 random_state=config.random_state) #set the hyperparams here\n",
    "        pipe = Pipeline([('clf',clf)])\n",
    "        pipe.fit(train.fillna(0).drop(['label'],axis=1),train['label'])\n",
    "        \n",
    "        #Make predictions\n",
    "        pred_val = pipe.predict(val.fillna(0).drop(['label'],axis=1))\n",
    "        pred_prob_val = pipe.predict_proba(val.fillna(0).drop(['label'],axis=1))[:,1]\n",
    "        accuracy = accuracy_score(val['label'],pred_val)\n",
    "        f1_macro = f1_score(val['label'],pred_val,average='macro')\n",
    "        if train['label'].nunique() <=2:\n",
    "            aucpc =  average_precision_score(val['label'],pred_prob_val)\n",
    "            auc = roc_auc_score(val['label'],pred_prob_val)\n",
    "            #Log predictions on WandB\n",
    "        else:\n",
    "            aucpc = '-'\n",
    "            auc = '-'\n",
    "        wandb.log({\"accuracy\": accuracy, \"f1 macro\":f1_macro, \"AUC-PC\":aucpc, 'AUC':auc })\n",
    "\n",
    "\n",
    "#Track emissions\n",
    "tracker = EmissionsTracker(project_name=name,log_level='warning', measure_power_secs=300,\n",
    "                           output_file='output/emissions_hyperopt.csv')\n",
    "#Launch the agent\n",
    "tracker.start()\n",
    "wandb.agent(sweep_id, train_fasttext, count=OPT_ITER)\n",
    "tracker.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text_class",
   "language": "python",
   "name": "text_class"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
