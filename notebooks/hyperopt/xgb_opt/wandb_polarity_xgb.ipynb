{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0b247f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjtonglet\u001b[0m (\u001b[33mbenchmark-nlp\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Saiga\\Documents\\NotebooksJupyter\\text_classification_benchmark\\notebooks\\hyperopt\\xgb_opt\\wandb\\run-20220826_101958-2l3qdp4a</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/benchmark-nlp/xgb/runs/2l3qdp4a\" target=\"_blank\">polarity datasets</a></strong> to <a href=\"https://wandb.ai/benchmark-nlp/xgb\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/benchmark-nlp/xgb/runs/2l3qdp4a?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x268ffad1760>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Connect to wandb\n",
    "#TO DO : how to save models on the weight and bias platform\n",
    "import wandb\n",
    "wandb.login()\n",
    "wandb.init(project=\"xgb\", \n",
    "           entity=\"benchmark-nlp\",\n",
    "           name='polarity datasets') #CHANGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0ea61cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir('../../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f333de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load packages\n",
    "import warnings\n",
    "import io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from codecarbon import EmissionsTracker\n",
    "import yaml\n",
    "from util.dataloader import DataLoader\n",
    "from preprocessing.preprocessor import Preprocessor\n",
    "from util.datasplitter import data_splitter\n",
    "from preprocessing.fasttext_embeddings import FastTextEmbeddings\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, average_precision_score\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0b20476",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set constant values\n",
    "SEED=42 \n",
    "OPT_ITER=20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2564a2",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b411fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "560000 rows preprocessed in 623.6616418361664 seconds\n",
      "38000 rows preprocessed in 41.488340616226196 seconds\n"
     ]
    }
   ],
   "source": [
    "dl = DataLoader(['polarity'])\n",
    "data = dl.load()\n",
    "\n",
    "\n",
    "tweet_preprocessor = Preprocessor(is_tweet=True)\n",
    "preprocessor = Preprocessor()\n",
    "\n",
    "#We are not interested in the test sets for hyperparameter optimization\n",
    "train_imdb, val_imdb, _ = data_splitter(data['imdb'],\n",
    "                                 preprocessor, \n",
    "                                 create_val_set=True,   #No validation set is provided\n",
    "                                 seed=SEED)\n",
    "train_yelp, val_yelp, _ = data_splitter(data['yelp'],\n",
    "                                 preprocessor, \n",
    "                                 create_val_set=True,   #No validation set is provided\n",
    "                                 seed=SEED)\n",
    "train_sst2, val_sst2, _ = data_splitter(data['sst2'],\n",
    "                                 preprocessor, \n",
    "                                 create_val_set=True,   #No validation set is provided\n",
    "                                 seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "010d1fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 22 s\n",
      "Wall time: 42.4 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#fasttext \n",
    "fasttext = FastTextEmbeddings()\n",
    "fasttext.load_model('fasttext/cc.en.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02866a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to generate sentence embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 20000/20000 [04:01<00:00, 82.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to generate sentence embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 5000/5000 [00:55<00:00, 90.38it/s]\n"
     ]
    }
   ],
   "source": [
    "embedded_train_imdb = fasttext.generate_sentence_embeddings(train_imdb['text'])\n",
    "embedded_val_imdb = fasttext.generate_sentence_embeddings(val_imdb['text'])\n",
    "embedded_train_imdb['label'] = train_imdb['label'].to_list()\n",
    "embedded_val_imdb['label'] = val_imdb['label'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa8081fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to generate sentence embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 448000/448000 [39:35<00:00, 188.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to generate sentence embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 112000/112000 [10:25<00:00, 178.95it/s]\n"
     ]
    }
   ],
   "source": [
    "embedded_train_yelp = fasttext.generate_sentence_embeddings(train_yelp['text'])\n",
    "embedded_val_yelp = fasttext.generate_sentence_embeddings(val_yelp['text'])\n",
    "embedded_train_yelp['label'] = train_yelp['label'].to_list()\n",
    "embedded_val_yelp['label'] = val_yelp['label'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72d0c50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to generate sentence embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 67349/67349 [02:03<00:00, 545.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to generate sentence embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 872/872 [00:01<00:00, 474.45it/s]\n"
     ]
    }
   ],
   "source": [
    "embedded_train_sst2 = fasttext.generate_sentence_embeddings(train_sst2['text'])\n",
    "embedded_val_sst2= fasttext.generate_sentence_embeddings(val_sst2['text'])\n",
    "embedded_train_sst2['label'] = train_sst2['label'].to_list()\n",
    "embedded_val_sst2['label'] = val_sst2['label'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b151bc98",
   "metadata": {},
   "source": [
    "## Hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "224ad24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "#Load the template yaml sweep config file for logistic regression\n",
    "#If the value range for an hyperparameter needs to be changed, better to do it in the .yaml file than in a notebook\n",
    "with open(\"config/xgb_sweep.yaml\", 'r') as stream:\n",
    "    sweep_config = yaml.safe_load(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "114df105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'method': 'random',\n",
       " 'entity': 'benchmark-nlp',\n",
       " 'project': 'hyperopt',\n",
       " 'metric': {'name': 'loss', 'goal': 'minimize'},\n",
       " 'parameters': {'gamma': {'min': 0, 'max': 1, 'distribution': 'uniform'},\n",
       "  'n_estimators': {'min': 10, 'max': 150, 'distribution': 'int_uniform'},\n",
       "  'learning_rate': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'},\n",
       "  'max_depth': {'min': 0, 'max': 10, 'distribution': 'int_uniform'},\n",
       "  'random_state': {'value': 42}}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The config is displayed as a nested dictionary\n",
    "sweep_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f1c508",
   "metadata": {},
   "source": [
    "#### imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9636bd33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Don't forget to name the sweep instance  \n",
    "name = 'xgb_tfidf_imdb' #change here\n",
    "sweep_config['name'] =  name\n",
    "\n",
    "#Generate a sweep_id\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"xgb\")\n",
    "\n",
    "def train_tfidf(config = None,\n",
    "          train=train_imdb, #Change here\n",
    "          val=val_imdb): #change here\n",
    "    '''\n",
    "    Generic WandB function to conduct hyperparameter optimization with tf-idf vectorizer\n",
    "    '''\n",
    "    # Initialize a new wandb run\n",
    "    with wandb.init(config=config,group=name):\n",
    "        # If called by wandb.agent, as below,\n",
    "        # this config will be set by Sweep Controller\n",
    "        config = wandb.config\n",
    "        vec = TfidfVectorizer()\n",
    "        clf = XGBClassifier(gamma=config.gamma,\n",
    "                                 n_estimators=config.n_estimators,\n",
    "                                 learning_rate=config.learning_rate,\n",
    "                                 max_depth=config.max_depth,\n",
    "                                 random_state=config.random_state) #set the hyperparams here\n",
    "        \n",
    "        #Create the pipeline\n",
    "        pipe = Pipeline([('vectorizer',vec),('clf',clf)])\n",
    "        #Fit the pipeline\n",
    "        pipe.fit(train['text'],train['label'])\n",
    "        \n",
    "        #Make predictions\n",
    "        pred_val = pipe.predict(val['text'])\n",
    "        pred_prob_val = pipe.predict_proba(val['text'])[:,1]\n",
    "        accuracy = accuracy_score(val['label'],pred_val)\n",
    "        f1_macro = f1_score(val['label'],pred_val,average='macro')\n",
    "        if train['label'].nunique() <=2:\n",
    "            aucpc =  average_precision_score(val['label'],pred_prob_val)\n",
    "            auc = roc_auc_score(val['label'],pred_prob_val)\n",
    "        else:\n",
    "            aucpc = '-'\n",
    "            auc = '-'\n",
    "        #Log metrics on WandB\n",
    "        wandb.log({\"accuracy\": accuracy, \"f1 macro\":f1_macro, \"AUC-PC\":aucpc, 'AUC':auc })\n",
    "\n",
    "#Track emissions\n",
    "tracker = EmissionsTracker(project_name=name,log_level='warning', measure_power_secs=300,\n",
    "                           output_file='output/emissions_hyperopt.csv')\n",
    "#Launch the agent\n",
    "tracker.start()\n",
    "wandb.agent(sweep_id, train_tfidf,count=OPT_ITER) #Count : number of iterations\n",
    "tracker.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d149865",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Don't forget to name the sweep instance   \n",
    "name = 'xgb_ft_imdb' #change here\n",
    "sweep_config['name'] = name\n",
    "#Generate a sweep_id\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"xgb\")\n",
    "\n",
    "def train_fasttext(config = None,\n",
    "          train=embedded_train_imdb, #Change here\n",
    "          val=embedded_val_imdb): #change here\n",
    "    # Initialize a new wandb run\n",
    "    with wandb.init(config=config, group=name):\n",
    "        # If called by wandb.agent, as below,\n",
    "        # this config will be set by Sweep Controller\n",
    "        config = wandb.config\n",
    "        clf = XGBClassifier(gamma=config.gamma,\n",
    "                                 n_estimators=config.n_estimators,\n",
    "                                 learning_rate=config.learning_rate,\n",
    "                                 max_depth=config.max_depth,\n",
    "                                 random_state=config.random_state) #set the hyperparams here\n",
    "        pipe = Pipeline([('clf',clf)])\n",
    "        pipe.fit(train.fillna(0).drop(['label'],axis=1),train['label'])\n",
    "        \n",
    "        #Make predictions\n",
    "        pred_val = pipe.predict(val.fillna(0).drop(['label'],axis=1))\n",
    "        pred_prob_val = pipe.predict_proba(val.fillna(0).drop(['label'],axis=1))[:,1]\n",
    "        accuracy = accuracy_score(val['label'],pred_val)\n",
    "        f1_macro = f1_score(val['label'],pred_val,average='macro')\n",
    "        if train['label'].nunique() <=2:\n",
    "            aucpc =  average_precision_score(val['label'],pred_prob_val)\n",
    "            auc = roc_auc_score(val['label'],pred_prob_val)\n",
    "            #Log predictions on WandB\n",
    "        else:\n",
    "            aucpc = '-'\n",
    "            auc = '-'\n",
    "        wandb.log({\"accuracy\": accuracy, \"f1 macro\":f1_macro, \"AUC-PC\":aucpc, 'AUC':auc })\n",
    "\n",
    "\n",
    "#Track emissions\n",
    "tracker = EmissionsTracker(project_name=name,log_level='warning', measure_power_secs=300,\n",
    "                           output_file='output/emissions_hyperopt.csv')\n",
    "#Launch the agent\n",
    "tracker.start()\n",
    "wandb.agent(sweep_id, train_fasttext,count=OPT_ITER)\n",
    "tracker.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a54da39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_imdb\n",
    "del val_imdb\n",
    "del embedded_train_imdb\n",
    "del embedded_val_imdb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fbc6d7",
   "metadata": {},
   "source": [
    "#### YELP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469357b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Don't forget to name the sweep instance  \n",
    "name = 'xgb_tfidf_yelp' #change here\n",
    "sweep_config['name'] =  name\n",
    "\n",
    "#Generate a sweep_id\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"xgb\")\n",
    "\n",
    "def train_tfidf(config = None,\n",
    "          train=train_yelp, #Change here\n",
    "          val=val_yelp): #change here\n",
    "    '''\n",
    "    Generic WandB function to conduct hyperparameter optimization with tf-idf vectorizer\n",
    "    '''\n",
    "    # Initialize a new wandb run\n",
    "    with wandb.init(config=config,group=name):\n",
    "        # If called by wandb.agent, as below,\n",
    "        # this config will be set by Sweep Controller\n",
    "        config = wandb.config\n",
    "        vec = TfidfVectorizer()\n",
    "        clf = XGBClassifier(gamma=config.gamma,\n",
    "                                 n_estimators=config.n_estimators,\n",
    "                                 learning_rate=config.learning_rate,\n",
    "                                 max_depth=config.max_depth,\n",
    "                                 random_state=config.random_state) #set the hyperparams here\n",
    "        \n",
    "        #Create the pipeline\n",
    "        pipe = Pipeline([('vectorizer',vec),('clf',clf)])\n",
    "        #Fit the pipeline\n",
    "        pipe.fit(train['text'],train['label'])\n",
    "        \n",
    "        #Make predictions\n",
    "        pred_val = pipe.predict(val['text'])\n",
    "        pred_prob_val = pipe.predict_proba(val['text'])[:,1]\n",
    "        accuracy = accuracy_score(val['label'],pred_val)\n",
    "        f1_macro = f1_score(val['label'],pred_val,average='macro')\n",
    "        if train['label'].nunique() <=2:\n",
    "            aucpc =  average_precision_score(val['label'],pred_prob_val)\n",
    "            auc = roc_auc_score(val['label'],pred_prob_val)\n",
    "        else:\n",
    "            aucpc = '-'\n",
    "            auc = '-'\n",
    "        #Log metrics on WandB\n",
    "        wandb.log({\"accuracy\": accuracy, \"f1 macro\":f1_macro, \"AUC-PC\":aucpc, 'AUC':auc })\n",
    "\n",
    "#Track emissions\n",
    "tracker = EmissionsTracker(project_name=name,log_level='warning', measure_power_secs=300,\n",
    "                           output_file='output/emissions_hyperopt.csv')\n",
    "#Launch the agent\n",
    "tracker.start()\n",
    "wandb.agent(sweep_id, train_tfidf,count=OPT_ITER)\n",
    "tracker.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830c6068",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Don't forget to name the sweep instance   \n",
    "name = 'xgb_ft_yelp' #CHANGE HERE\n",
    "sweep_config['name'] = name\n",
    "#Generate a sweep_id\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"xgb\")\n",
    "\n",
    "def train_fasttext(config = None,\n",
    "          train=embedded_train_yelp, #CHANGE HERE\n",
    "          val=embedded_val_yelp): #CHANGE HERE\n",
    "    # Initialize a new wandb run\n",
    "    with wandb.init(config=config, group=name):\n",
    "        config = wandb.config\n",
    "        clf = XGBClassifier(gamma=config.gamma,\n",
    "                                 n_estimators=config.n_estimators,\n",
    "                                 learning_rate=config.learning_rate,\n",
    "                                 max_depth=config.max_depth,\n",
    "                                 random_state=config.random_state) #set the hyperparams here\n",
    "        pipe = Pipeline([('clf',clf)])\n",
    "        pipe.fit(train.fillna(0).drop(['label'],axis=1),train['label'])\n",
    "        \n",
    "        #Make predictions\n",
    "        pred_val = pipe.predict(val.fillna(0).drop(['label'],axis=1))\n",
    "        pred_prob_val = pipe.predict_proba(val.fillna(0).drop(['label'],axis=1))[:,1]\n",
    "        accuracy = accuracy_score(val['label'],pred_val)\n",
    "        f1_macro = f1_score(val['label'],pred_val,average='macro')\n",
    "        if train['label'].nunique() <=2:\n",
    "            aucpc =  average_precision_score(val['label'],pred_prob_val)\n",
    "            auc = roc_auc_score(val['label'],pred_prob_val)\n",
    "            #Log predictions on WandB\n",
    "        else:\n",
    "            aucpc = '-'\n",
    "            auc = '-'\n",
    "        wandb.log({\"accuracy\": accuracy, \"f1 macro\":f1_macro, \"AUC-PC\":aucpc, 'AUC':auc })\n",
    "\n",
    "\n",
    "#Track emissions\n",
    "tracker = EmissionsTracker(project_name=name,log_level='warning', measure_power_secs=300,\n",
    "                           output_file='output/emissions_hyperopt.csv')\n",
    "#Launch the agent\n",
    "tracker.start()\n",
    "wandb.agent(sweep_id, train_fasttext,count=OPT_ITER)\n",
    "tracker.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71a6f28",
   "metadata": {},
   "source": [
    "#### sst2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43086bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Don't forget to name the sweep instance  \n",
    "name = 'xgb_tfidf_sst2' #change here\n",
    "sweep_config['name'] =  name\n",
    "\n",
    "#Generate a sweep_id\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"xgb\")\n",
    "\n",
    "def train_tfidf(config = None,\n",
    "          train=train_sst2, #Change here\n",
    "          val=val_sst2): #change here\n",
    "    '''\n",
    "    Generic WandB function to conduct hyperparameter optimization with tf-idf vectorizer\n",
    "    '''\n",
    "    # Initialize a new wandb run\n",
    "    with wandb.init(config=config,group=name):\n",
    "        # If called by wandb.agent, as below,\n",
    "        # this config will be set by Sweep Controller\n",
    "        config = wandb.config\n",
    "        vec = TfidfVectorizer()\n",
    "        clf = XGBClassifier(gamma=config.gamma,\n",
    "                                 n_estimators=config.n_estimators,\n",
    "                                 learning_rate=config.learning_rate,\n",
    "                                 max_depth=config.max_depth,\n",
    "                                 random_state=config.random_state) #set the hyperparams here\n",
    "        \n",
    "        #Create the pipeline\n",
    "        pipe = Pipeline([('vectorizer',vec),('clf',clf)])\n",
    "        #Fit the pipeline\n",
    "        pipe.fit(train['text'],train['label'])\n",
    "        \n",
    "        #Make predictions\n",
    "        pred_val = pipe.predict(val['text'])\n",
    "        pred_prob_val = pipe.predict_proba(val['text'])[:,1]\n",
    "        accuracy = accuracy_score(val['label'],pred_val)\n",
    "        f1_macro = f1_score(val['label'],pred_val,average='macro')\n",
    "        if train['label'].nunique() <=2:\n",
    "            aucpc =  average_precision_score(val['label'],pred_prob_val)\n",
    "            auc = roc_auc_score(val['label'],pred_prob_val)\n",
    "        else:\n",
    "            aucpc = '-'\n",
    "            auc = '-'\n",
    "        #Log metrics on WandB\n",
    "        wandb.log({\"accuracy\": accuracy, \"f1 macro\":f1_macro, \"AUC-PC\":aucpc, 'AUC':auc })\n",
    "\n",
    "#Track emissions\n",
    "tracker = EmissionsTracker(project_name=name,log_level='warning', measure_power_secs=300,\n",
    "                           output_file='output/emissions_hyperopt.csv')\n",
    "#Launch the agent\n",
    "tracker.start()\n",
    "wandb.agent(sweep_id, train_tfidf, count=OPT_ITER)\n",
    "tracker.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c304fc6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Don't forget to name the sweep instance   \n",
    "name = 'xgb_ft_sst2' #CHANGE HERE\n",
    "sweep_config['name'] = name\n",
    "#Generate a sweep_id\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"xgb\")\n",
    "\n",
    "def train_fasttext(config = None,\n",
    "          train=embedded_train_sst2, #CHANGE HERE\n",
    "          val=embedded_val_sst2): #CHANGE HERE\n",
    "    # Initialize a new wandb run\n",
    "    with wandb.init(config=config, group=name):\n",
    "        config = wandb.config\n",
    "        clf = XGBClassifier(gamma=config.gamma,\n",
    "                                 n_estimators=config.n_estimators,\n",
    "                                 learning_rate=config.learning_rate,\n",
    "                                 max_depth=config.max_depth,\n",
    "                                 random_state=config.random_state) #set the hyperparams here\n",
    "        pipe = Pipeline([('clf',clf)])\n",
    "        pipe.fit(train.fillna(0).drop(['label'],axis=1),train['label'])\n",
    "        \n",
    "        #Make predictions\n",
    "        pred_val = pipe.predict(val.fillna(0).drop(['label'],axis=1))\n",
    "        pred_prob_val = pipe.predict_proba(val.fillna(0).drop(['label'],axis=1))[:,1]\n",
    "        accuracy = accuracy_score(val['label'],pred_val)\n",
    "        f1_macro = f1_score(val['label'],pred_val,average='macro')\n",
    "        if train['label'].nunique() <=2:\n",
    "            aucpc =  average_precision_score(val['label'],pred_prob_val)\n",
    "            auc = roc_auc_score(val['label'],pred_prob_val)\n",
    "            #Log predictions on WandB\n",
    "        else:\n",
    "            aucpc = '-'\n",
    "            auc = '-'\n",
    "        wandb.log({\"accuracy\": accuracy, \"f1 macro\":f1_macro, \"AUC-PC\":aucpc, 'AUC':auc })\n",
    "\n",
    "\n",
    "#Track emissions\n",
    "tracker = EmissionsTracker(project_name=name,log_level='warning', measure_power_secs=300,\n",
    "                           output_file='output/emissions_hyperopt.csv')\n",
    "#Launch the agent\n",
    "tracker.start()\n",
    "wandb.agent(sweep_id, train_fasttext, count=OPT_ITER)\n",
    "tracker.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c18929d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_sst2\n",
    "del val_sst2\n",
    "del embedded_train_sst2\n",
    "del embedded_val_sst2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text_class",
   "language": "python",
   "name": "text_class"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
