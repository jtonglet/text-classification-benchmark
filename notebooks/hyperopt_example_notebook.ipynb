{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a46c1fb",
   "metadata": {},
   "source": [
    "## Example notebook for hyperparameter optimization with Weight & Biases  (Logistic Regression - Emotion datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0b247f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjtonglet\u001b[0m (\u001b[33mbenchmark-nlp\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Saiga\\Documents\\NotebooksJupyter\\text_classification_benchmark\\notebooks\\wandb\\run-20220810_105125-tvssxha0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/benchmark-nlp/hyperopt/runs/tvssxha0\" target=\"_blank\">emotion datasets</a></strong> to <a href=\"https://wandb.ai/benchmark-nlp/hyperopt\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/benchmark-nlp/hyperopt/runs/tvssxha0?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x2162a9f00c8>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Connect to wandb\n",
    "import wandb\n",
    "wandb.login()\n",
    "wandb.init(project=\"hyperopt\", \n",
    "           entity=\"benchmark-nlp\",\n",
    "           name='emotion datasets') #CHANGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e00a271",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f333de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load packages\n",
    "import warnings\n",
    "import io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from codecarbon import EmissionsTracker\n",
    "import yaml\n",
    "from util.dataloader import DataLoader\n",
    "from util.datasplitter import data_splitter\n",
    "from preprocessing.preprocessor import Preprocessor\n",
    "from preprocessing.fasttext_embeddings import FastTextEmbeddings\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, average_precision_score\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0b20476",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set constant values\n",
    "SEED=42 \n",
    "OPT_ITER=10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2564a2",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b411fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3257 rows preprocessed in 3.270162582397461 seconds\n",
      "1421 rows preprocessed in 0.38402867317199707 seconds\n",
      "374 rows preprocessed in 0.08252835273742676 seconds\n",
      "16000 rows preprocessed in 4.920097351074219 seconds\n",
      "2000 rows preprocessed in 0.675194501876831 seconds\n",
      "2000 rows preprocessed in 0.49068760871887207 seconds\n",
      "87170 rows preprocessed in 17.7122962474823 seconds\n",
      "7740 rows preprocessed in 1.4251904487609863 seconds\n",
      "8069 rows preprocessed in 1.5209741592407227 seconds\n"
     ]
    }
   ],
   "source": [
    "dl = DataLoader(['emotion'])\n",
    "data = dl.load()\n",
    "\n",
    "tweet_preprocessor = Preprocessor(is_tweet=True)\n",
    "preprocessor = Preprocessor()\n",
    "#We are not interested in the test sets for hyperparameter optimization\n",
    "train_eval_emotion, val_eval_emotion, _ = data_splitter(data['tweetEval'],\n",
    "                                 tweet_preprocessor, \n",
    "                                 seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010d1fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#Load fasttext \n",
    "fasttext = FastTextEmbeddings()\n",
    "fasttext.load_model('fasttext/cc.en.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02866a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_train_eval_emotion = fasttext.generate_sentence_embeddings(train_eval_emotion['text'])\n",
    "embedded_val_eval_emotion = fasttext.generate_sentence_embeddings(val_eval_emotion['text'])\n",
    "embedded_train_eval_emotion['label'] = train_eval_emotion['label'].to_list()\n",
    "embedded_val_eval_emotion['label'] = val_eval_emotion['label'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b151bc98",
   "metadata": {},
   "source": [
    "## Hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224ad24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "#Load the template yaml sweep config file for logistic regression\n",
    "with open(\"config/lr_sweep.yaml\", 'r') as stream:\n",
    "    sweep_config = yaml.safe_load(stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f1c508",
   "metadata": {},
   "source": [
    "#### eval emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9636bd33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Name the sweep instance \n",
    "name = 'lr_tfidf_eval_emotion' #change here\n",
    "sweep_config['name'] =  name\n",
    "\n",
    "#Generate a sweep_id\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"hyperopt\")\n",
    "\n",
    "def train_tfidf(config = None,\n",
    "          train=train_eval_emotion, #Change here\n",
    "          val=val_eval_emotion): #change here\n",
    "    # Initialize a new wandb run\n",
    "    with wandb.init(config=config,group=name):\n",
    "        # If called by wandb.agent, as below,\n",
    "        # this config will be set by Sweep Controller\n",
    "        config = wandb.config\n",
    "        vec = TfidfVectorizer()\n",
    "        clf = LogisticRegression(C = config.C,\n",
    "                                 penalty = config.penalty,\n",
    "                                 solver = config.solver,\n",
    "                                 random_state=config.random_state) #set the hyperparams here\n",
    "        \n",
    "        #Create the pipeline\n",
    "        pipe = Pipeline([('vectorizer',vec),('clf',clf)])\n",
    "        #Fit the pipeline\n",
    "        pipe.fit(train['text'],train['label'])\n",
    "        \n",
    "        #Make predictions\n",
    "        pred_val = pipe.predict(val['text'])\n",
    "        pred_prob_val = pipe.predict_proba(val['text'])[:,1]\n",
    "        accuracy = accuracy_score(val['label'],pred_val)\n",
    "        f1_macro = f1_score(val['label'],pred_val,average='macro')\n",
    "        if train['label'].nunique() <=2:\n",
    "            aucpc =  average_precision_score(val['label'],pred_prob_val)\n",
    "            auc = roc_auc_score(val['label'],pred_prob_val)\n",
    "        else:\n",
    "            aucpc = '-'\n",
    "            auc = '-'\n",
    "        #Log metrics on WandB\n",
    "        wandb.log({\"accuracy\": accuracy, \"f1 macro\":f1_macro, \"AUC-PC\":aucpc, 'AUC':auc })\n",
    "\n",
    "#Track emissions\n",
    "tracker = EmissionsTracker(project_name=name,log_level='warning', measure_power_secs=300,\n",
    "                           output_file='output/emissions_hyperopt.csv')\n",
    "#Launch the agent\n",
    "tracker.start()\n",
    "wandb.agent(sweep_id, train_tfidf,count=OPT_ITER) #Count : number of iterations\n",
    "tracker.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d149865",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "name = 'lr_ft_eval_emotion' #change here\n",
    "sweep_config['name'] = name\n",
    "#Generate a sweep_id\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"hyperopt\")\n",
    "\n",
    "def train_fasttext(config = None,\n",
    "          train=embedded_train_eval_emotion, #Change here\n",
    "          val=embedded_val_eval_emotion): #change here\n",
    "    # Initialize a new wandb run\n",
    "    with wandb.init(config=config, group=name):\n",
    "        # If called by wandb.agent, as below,\n",
    "        # this config will be set by Sweep Controller\n",
    "        config = wandb.config\n",
    "        clf = LogisticRegression(C = config.C,\n",
    "                                 penalty = config.penalty,\n",
    "                                 solver = config.solver,\n",
    "                                 random_state=config.random_state) #set the hyperparams here\n",
    "        pipe = Pipeline([('clf',clf)])\n",
    "        pipe.fit(train.fillna(0).drop(['label'],axis=1),train['label'])\n",
    "        \n",
    "        #Make predictions\n",
    "        pred_val = pipe.predict(val.fillna(0).drop(['label'],axis=1))\n",
    "        pred_prob_val = pipe.predict_proba(val.fillna(0).drop(['label'],axis=1))[:,1]\n",
    "        accuracy = accuracy_score(val['label'],pred_val)\n",
    "        f1_macro = f1_score(val['label'],pred_val,average='macro')\n",
    "        if train['label'].nunique() <=2:\n",
    "            aucpc =  average_precision_score(val['label'],pred_prob_val)\n",
    "            auc = roc_auc_score(val['label'],pred_prob_val)\n",
    "            #Log predictions on WandB\n",
    "        else:\n",
    "            aucpc = '-'\n",
    "            auc = '-'\n",
    "        wandb.log({\"accuracy\": accuracy, \"f1 macro\":f1_macro, \"AUC-PC\":aucpc, 'AUC':auc })\n",
    "\n",
    "\n",
    "#Track emissions\n",
    "tracker = EmissionsTracker(project_name=name,log_level='warning', measure_power_secs=300,\n",
    "                           output_file='output/emissions_hyperopt.csv')\n",
    "#Launch the agent\n",
    "tracker.start()\n",
    "wandb.agent(sweep_id, train_fasttext,count=OPT_ITER)\n",
    "tracker.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
